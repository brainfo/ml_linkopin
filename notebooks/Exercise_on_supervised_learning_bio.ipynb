{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise on supervised learning\n",
    "\n",
    "In this exercise, you will train machine learning methods to predict if a person has a heart disease.\n",
    "\n",
    "The goal is to learn:\n",
    "*\thow to apply different ML classification methods.\n",
    "*\thow to perform cross-validation.\n",
    "*\thow to assess and visualize the performance.\n",
    "*\thow to get an idea on which features are most important.\n",
    "\n",
    "You will be using the same titantic dataset as you worked with on Monday, but instead of visualizing it and calculating properties you will be training ML methods to predict the chance of survival. You will train different ML methods using different parameters and different features using cross-validation to evaluate performance. For each ML method, you should save your final model, so you can load it and use it for predicting on new data later. Once you have trained and optimized a few ML methods, you will be given a new independent test set to finally check your performance on completely unseen data. We will compare which ML methods performed best, what was the cross-validated performance and what was the test set performance. Hopefully we will choose slightly different methods and training parameters, so we can compare what seems to work best.\n",
    "\n",
    "We start by reading in the data....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#This is just some code to split the data and get the 'secret' test set as 20%\n",
    "#data=pd.read_csv('heart_all_data.csv')\n",
    "#mask = np.random.rand(len(data)) < 0.8\n",
    "#train = data[mask]\n",
    "#test = data[~mask]\n",
    "#train.to_csv('heart_train.csv',index=False)\n",
    "#test.to_csv('heart_test.csv',index=False)\n",
    "\n",
    "#Read in the data to a pandas DataFrame using the read_csv method.\n",
    "train=pd.read_csv('heart_train.csv')\n",
    "\n",
    "# We are using the train data as placeholder for the test data,\n",
    "# so we can implement code to run predictions on the test pandas DataFrame as well.\n",
    "test=train.copy() \n",
    "\n",
    "#Uncomment this line to read in the true test, it will be revealed in due time....\n",
    "#test=pd.read_csv('heart_test.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of columns\n",
    "\n",
    "- **age**: The person's age in years\n",
    "- **sex**: The person's sex (1 = male, 0 = female)\n",
    "- **cp:** The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n",
    "- **trestbps:** The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "- **chol:** The person's cholesterol measurement in mg/dl\n",
    "- **fbs:** The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false) \n",
    "- **restecg:** Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n",
    "- **thalach:** The person's maximum heart rate achieved\n",
    "- **exang:** Exercise induced angina (1 = yes; 0 = no)\n",
    "- **oldpeak:** ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more [here](https://litfl.com/st-segment-ecg-library/))\n",
    "- **slope:** the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n",
    "- **ca:** The number of major vessels (0-3)\n",
    "- **thal:** A blood disorder called thalassemia (1 = normal; 2 = fixed defect; 3 = reversable defect)\n",
    "- **target:** Heart disease (0 = no, 1 = yes)\n",
    "\n",
    "The column names are abbreviations, we can change the column names by providing a list of equal size with the new names, like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns and at categorize as we did on monday.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to do the categorization\n",
    "def categorize(df):\n",
    "    df.loc[df['sex']==0,'sex']='female'\n",
    "    df.loc[df['sex']==1,'sex']='male'\n",
    "    df.loc[df['chest_pain_type'] == 1,'chest_pain_type'] = 'typical angina'\n",
    "    df.loc[df['chest_pain_type'] == 2,'chest_pain_type'] = 'atypical angina'\n",
    "    df.loc[df['chest_pain_type'] == 3,'chest_pain_type'] = 'non-anginal pain'\n",
    "    df.loc[df['chest_pain_type'] == 4,'chest_pain_type'] = 'asymptomatic'\n",
    "\n",
    "    df.loc[df['fasting_blood_sugar'] == 0,'fasting_blood_sugar'] = 'lower than 120mg/ml'\n",
    "    df.loc[df['fasting_blood_sugar'] == 1,'fasting_blood_sugar'] = 'greater than 120mg/ml'\n",
    "\n",
    "    df.loc[df['rest_ecg'] == 0,'rest_ecg'] = 'normal'\n",
    "    df.loc[df['rest_ecg'] == 1,'rest_ecg'] = 'ST-T wave abnormality'\n",
    "    df.loc[df['rest_ecg'] == 2,'rest_ecg'] = 'left ventricular hypertrophy'\n",
    "\n",
    "    df.loc[df['exercise_induced_angina'] == 0,'exercise_induced_angina'] = 'no'\n",
    "    df.loc[df['exercise_induced_angina'] == 1,'exercise_induced_angina'] = 'yes'\n",
    "\n",
    "    df.loc[df['st_slope'] == 1,'st_slope'] = 'upsloping'\n",
    "    df.loc[df['st_slope'] == 2,'st_slope'] = 'flat'\n",
    "    df.loc[df['st_slope'] == 3,'st_slope'] = 'downsloping'\n",
    "\n",
    "    df.loc[df['thalassemia'] == 1,'thalassemia'] = 'normal'\n",
    "    df.loc[df['thalassemia'] == 2,'thalassemia'] = 'fixed defect'\n",
    "    df.loc[df['thalassemia'] == 3,'thalassemia'] = 'reversable defect'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'sex', 'chest_pain_type', \n",
    "                 'resting_blood_pressure', 'cholesterol', \n",
    "                 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate',\n",
    "       'exercise_induced_angina', 'st_depression', 'st_slope', \n",
    "                 'num_major_vessels', 'thalassemia', 'target']\n",
    "\n",
    "train.columns=columns\n",
    "test.columns=columns\n",
    "\n",
    "#make a copy before changing.\n",
    "train_orig=train.copy()\n",
    "test_orig=test.copy()\n",
    "categorize(train)\n",
    "categorize(test)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also convert them to dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.get_dummies(train)\n",
    "df_test=pd.get_dummies(test)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation sets\n",
    "Cross-validation is a way to estimate performance by training and testing on subsets of the data. Usually it is common to divide the data into 5 parts (with no similarity between them). If there is no similarity between the data points, the division can be random. But usually there is some connection between data points. In the case of training on sequence data, sequence similarity is commonly used to group data points. \n",
    "\n",
    "In this case it is OK to do cross-validation randomly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "For some machine learning methods, e.g. SVM, scaling the features between 0-1 can improve the convergence and performance. Use the same `preprocessing.MinMaxScalar()` from `sklearn` as we used on Monday. If you want you can choose to compare the performance of scaling vs. no scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df=df_train\n",
    "#Pick the columns that have numbers that can be used for training:\n",
    "columns_to_scale=[c for c in df.columns if c !='target']\n",
    "\n",
    "#Make train_data and test_data to be used for training and testing.\n",
    "#We are using the one with the dummy variable, one-hot encoded.\n",
    "train_data=df_train.copy()\n",
    "test_data=df_test.copy()\n",
    "\n",
    "\n",
    "scaling=True\n",
    "#Uncomment to turn on scaling\n",
    "#scaling=True\n",
    "if scaling:\n",
    "    # Fit the scaler on the training data\n",
    "    # OBS If you do scaling you have to save \n",
    "    # the scaling parameters from the training set you know how to scale unknown examples in the prediction face.\n",
    "    min_max_scaler.fit(train_data[columns_to_scale].values)\n",
    "    # Transform the scaling to the train_data\n",
    "    train_data.loc[:,columns_to_scale]=min_max_scaler.transform(train_data[columns_to_scale].values)\n",
    "    # Transform the scaling to the test_data\n",
    "    test_data.loc[:,columns_to_scale]=min_max_scaler.transform(test_data[columns_to_scale].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data for training.\n",
    "Set up the data by making a numpy matrix of the training data called `X`, numpy vector with the target values `Y`, and if you are using cross-validitation use the PreDefinedSplit class (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html) to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "#Put the training data in X the .values method returns a numpy matrix of the numbers in the DataFrame.\n",
    "trainable_cols=[a for a in train_data.columns if a!='target']\n",
    "X=train_data[trainable_cols].values #,0:target_index]\n",
    "\n",
    "#Create the same for the test (currently this is the same as train just to keep to code running)\n",
    "X_test=test_data[trainable_cols].values\n",
    "\n",
    "#Put the target value in Y\n",
    "Y=train_data['target'].values\n",
    "Y_test=test_data['target'].values\n",
    "\n",
    "#Use the PredefinedSplit class to define the cross-validation sets.\n",
    "#Here it is random, but it could be based on some initial clustering of data. \n",
    "#Like sequence similarity, same 'patient', same/similar 'something'\n",
    "folds=5\n",
    "np.random.seed(42) #for reproducibility\n",
    "cv = PredefinedSplit((np.random.rand(len(train_data))*folds).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Machine Learning Methods\n",
    "Finally we can train machine learning methods... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the functions\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Define a function to calculate performance.\n",
    "def calc_performance(correct,pred,pred_prob,name='',plot=False):\n",
    "    acc=accuracy_score(correct,pred)\n",
    "    mcc=matthews_corrcoef(correct,pred)\n",
    "    f1=f1_score(correct,pred)\n",
    "    if plot:\n",
    "        (prec,recall,thres)=precision_recall_curve(correct,pred_prob)\n",
    "        (fpr,tpr,thres_roc)=roc_curve(correct,pred_prob)   \n",
    "        plt.plot(fpr,tpr)\n",
    "        plt.title(f'ROC curve {name}')\n",
    "        plt.xlabel('fpr')\n",
    "        plt.ylabel('tpr')\n",
    "        plt.show()\n",
    "        plt.plot(prec,recall)\n",
    "        plt.title(f'Prec-Recall curve {name}')\n",
    "        plt.xlabel('Prec')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.show()\n",
    "    return(acc,mcc,f1)\n",
    "\n",
    "\n",
    "\n",
    "#define a function to do the training using predefined splits\n",
    "\n",
    "def train_ml(clf,X,Y,cv,verbose=True,plot=False,name=''):\n",
    "\n",
    "    print(clf)\n",
    "    #Some lists to store cross-validated predictions\n",
    "    pred_save=[]\n",
    "    true_save=[]\n",
    "    pred_prob_save=[]\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(cv.split(),1):\n",
    "        if verbose:\n",
    "            print(\"Set: \",i)\n",
    "            print(\"Training on\",len(train_index),\"examples\")\n",
    "            print(\"Validating on\",len(val_index),\"examples\")\n",
    "        (X_train, X_val) = X[train_index,:], X[val_index,:]\n",
    "        (Y_train, Y_val) = Y[train_index], Y[val_index]\n",
    "  \n",
    "        #Perform the training (fitting)\n",
    "        clf=clf.fit(X_train,Y_train)\n",
    "       \n",
    "        #Predict on the training data    \n",
    "        pred=clf.predict(X_train) #gives 0/1\n",
    "        try:\n",
    "            pred_prob=clf.predict_proba(X_train)[:,1] #gives a probability used in Roc plots.\n",
    "        except:\n",
    "            pred_prob=pred\n",
    "        #Calculate performance measures on the training data\n",
    "        (acc_train,mcc_train,f1_train)=calc_performance(pred,Y_train,pred_prob,plot=False)\n",
    "\n",
    "    \n",
    "        #Predict on the validation data\n",
    "        \n",
    "        val_pred=clf.predict(X_val)      \n",
    "        try:\n",
    "            val_pred_prob=clf.predict_proba(X_val)[:,1]\n",
    "        except:\n",
    "            val_pred_prob=val_pred\n",
    "        #Save the values to have predictions for all folds.\n",
    "        pred_save.append(val_pred)\n",
    "        pred_prob_save.append(val_pred_prob)\n",
    "        true_save.append(Y_val)\n",
    "        #Calculate performance measures on the validation data\n",
    "        (acc,mcc,f1)=calc_performance(Y_val,val_pred,val_pred_prob,plot=False)\n",
    "        if verbose:\n",
    "            print(\"Training performance\",\"f1:\",f1_train,\"acc:\",acc_train,\"mcc:\",mcc_train)\n",
    "            print(\"Validation performance\",\"f1:\",f1,\"acc:\",acc,\"mcc:\",mcc)\n",
    "            print(\"==============\")\n",
    "\n",
    "     \n",
    "   \n",
    "\n",
    "    #Concatenate the predictions for all folds to one vector\n",
    "    predictions=np.concatenate(pred_save)\n",
    "    correct=np.concatenate(true_save)\n",
    "    predicted_prob=np.concatenate(pred_prob_save)\n",
    "\n",
    "    #Calculate overall validation performance\n",
    "    if verbose:\n",
    "        print(f'ML Algorithm: {clf}')\n",
    "    (acc,mcc,f1)=calc_performance(correct,predictions,predicted_prob,plot=plot,name=name)\n",
    "    print(f\"Overall Validation Performance f1 {f1} acc: {acc} mcc: {mcc}\")\n",
    "    #returns the correct, predictions, and predicted_prob for the cross-validation.\n",
    "    #the inputed clf is a reference and will change.\n",
    "    return(correct,predictions,predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Define a ML algorithm to use.\n",
    "#Feel free to check the sci-kit learn docs for the different algorithms to use\n",
    "#and the specific options and details on the hyperparameters.\n",
    "#Make sure you are are using method for Classification and not Regression\n",
    "\n",
    "\n",
    "\n",
    "#Go back and change the trainable features / scaling, trying to figure out which method to use.\n",
    "#Which method gives best performance on the validation data?\n",
    "#What are the minimal number of features you need and still reach good performance on validation?\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, n_jobs=4,random_state=None,verbose=0)\n",
    "#clf = svm.SVC(kernel='linear',verbose=1, probability=True)\n",
    "#clf = linear_model.LogisticRegression(max_iter=1000)\n",
    "#clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "#clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "clf_log = linear_model.LogisticRegression(max_iter=1000)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf_log,X,Y,cv,verbose=False,plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(max_iter=1000)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "(prec,recall,thres)=precision_recall_curve(correct,predicted_prob)\n",
    "acc=accuracy_score(correct,predictions)\n",
    "mcc=matthews_corrcoef(correct,predictions)\n",
    "f1=f1_score(correct,predictions) \n",
    "#plt.clf()\n",
    "#plt.plot(thres_roc,fpr)\n",
    "#plt.plot(thres_roc,tpr)\n",
    "plt.plot(fpr,tpr,label='DecisionTree')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='DecisionTree5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='KN-uniform')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf',C=0.1) #I had problems using kernel='linear' got stuck in a loop /BW\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='SVMrbf')\n",
    "plt.legend()\n",
    "\n",
    "clf = svm.LinearSVC(max_iter=1000)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='SVMlinear')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='KN-uniform')\n",
    "plt.legend()\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)   \n",
    "plt.plot(fpr,tpr,label='KN-distance')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "#clf = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, n_jobs=4,random_state=None,verbose=0)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='RF_no_MAX')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "clf_RF10 = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, n_jobs=4,random_state=None,verbose=0)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf_RF10,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='RF_10')\n",
    "\n",
    "clf_RF = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=2, n_jobs=4,random_state=None,verbose=0)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf_RF,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='RF_5')\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_split=2, n_jobs=4,random_state=None,verbose=0)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='RF_3')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='DecisionTree')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='DecisionTree5')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='DecisionTree10')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "plt.plot(fpr,tpr,label='DecisionTree2')\n",
    "plt.legend()\n",
    "\n",
    "#clf = DecisionTreeClassifier(max_depth=5,splitter='random')\n",
    "#(correct,predictions,predicted_prob)=train_ml(clf,X,Y,cv,verbose=False,plot=False)\n",
    "#(fpr,tpr,thres_roc)=roc_curve(correct,predicted_prob)\n",
    "#plt.plot(fpr,tpr,label='DecisionTree5-rand')\n",
    "#plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test (this is identical to the train set until the true test is revealed.)\n",
    "#Assumes the optimized ML method is defined as clf\n",
    "clf=clf_log\n",
    "\n",
    "\n",
    "test_correct=Y_test\n",
    "test_pred=clf.predict(X_test)      \n",
    "test_pred_prob=clf.predict_proba(X_test) \n",
    "\n",
    "(fpr,tpr,thres_roc)=roc_curve(test_correct,test_pred_prob[:,1])\n",
    "plt.plot(fpr,tpr,label='logistic')\n",
    "(acc,mcc,f1)=calc_performance(test_correct,test_pred,test_pred_prob[:,1],plot=True)\n",
    "print(\"Overall Test Performance\",\"f1:\",f1,\"acc:\",acc,\"mcc:\",mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=clf_RF10\n",
    "test_correct=Y_test\n",
    "test_pred=clf.predict(X_test)      \n",
    "test_pred_prob=clf.predict_proba(X_test) \n",
    "\n",
    "#(fpr,tpr,thres_roc)=roc_curve(test_correct,test_pred_prob[:,1])\n",
    "#plt.plot(fpr,tpr,label='RF')\n",
    "#plt.legend()\n",
    "(acc,mcc,f1)=calc_performance(test_correct,test_pred,test_pred_prob[:,1],plot=True)\n",
    "print(\"Overall Test Performance\",\"f1:\",f1,\"acc:\",acc,\"mcc:\",mcc)\n",
    "\n",
    "(prec,recall,thres)=precision_recall_curve(test_correct,test_pred_prob[:,1])\n",
    "plt.plot(prec,recall,label='RF')\n",
    "#len(thres)\n",
    "#len(prec)\n",
    "plt.show()\n",
    "plt.plot(thres,prec[1:],label='prec')\n",
    "plt.plot(thres,recall[1:],label='recall')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are using decision trees you check the importance of each feature\n",
    "#it will complain if 'clf' does not have the 'feature_importances_' method.\n",
    "\n",
    "try:\n",
    "    for feature, importance in zip(trainable_cols,clf_RF.feature_importances_):\n",
    "        print(f'{feature:18s} {importance:.3f}')\n",
    "except:\n",
    "    print('Probably clf does not have feature_importances_ method')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
